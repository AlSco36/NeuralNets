{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE495 In-class Exercise 2: Spiking Neural Networks using NengoDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ICE uses NengoDL and TensorFlow's Keras to:\n",
    "\n",
    "1. Load a prebuilt dataset.\n",
    "2. Build a simple *spiking* neural network that classifies images.\n",
    "3. Train the spiking neural network.\n",
    "4. Evaluate the accuracy of the spiking network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up\n",
    "\n",
    "**Ensure you are using your [495 Virtual Environment](https://github.com/kaitlin-fair/495venv_setup) before you begin!**  \n",
    "  \n",
    "If you are using your virtual environment, the next section should run without issue. If you are not in your virtual environment (or your environment did not install properly), you'll see a lot of red.\n",
    "  \n",
    "Import Nengo, NengoDL, TensorFlow and other supporting libraries into your program to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "import nengo\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nengo_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset\n",
    "\n",
    "Load and prepare the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database). The pixel values of the images range from 0 through 255. Recall in ICE1, we had to normalize the values. For this spiking neural network, we do not have to do that. _Ensure you understand why we don't have to normalize the input values._\n",
    "\n",
    "Add info about input nodes only being able to accept a vector and how the data is encoded to be sent into the network. [deets here](https://forum.nengo.ai/t/how-are-spikes-generated-within-nengodl/2130). Then have students pre-process the data so it's already flat going in.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .questioncolor {\n",
    "        background-color: #906752;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "<div class=\"questioncolor\">\n",
    "\n",
    "This is the first section you are required to edit!\n",
    "1. Grab the dataset from tf.keras. [Look here](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to see the different datasets that TensorFlow Keras has at the ready and find commands to load the dataset. Replace `???` with the correct command on the first line. If you look further in TensorFlow documentation, you may see that there are other ways to call the MNIST dataset. It will be easiest within this notebook to use the command that begins with `tf.keras`.\n",
    "2. Normalize the pixel values of the entire dataset. Replace the appropriate `???` to do so.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# flatten images - note that they do not use a layer that flattens\n",
    "#   the data and instead pre-process the data to flatten \n",
    "#   The layer cannot handle a 4 dimensional input = image#, timestep, xdim, ydim\n",
    "#   Flatten to make it 3-D: image#, timestep, xdim*ydim\n",
    "train_images = train_images.reshape((train_images.shape[0], -1))\n",
    "test_images = test_images.reshape((test_images.shape[0], -1))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(np.reshape(train_images[i], (28, 28)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(str(train_labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all deep learning methods are based on gradient descent, which means that the network being optimized needs to be differentiable. Deep neural networks are usually built using rectified linear or sigmoid neurons, as these are differentiable nonlinearities. However, in neurmorphic modelling we often want to use spiking neurons, which are not differentiable. So the challenge is how to apply deep learning methods to spiking neural networks.\n",
    "\n",
    "A method for accomplishing this is presented in Hunsberger and Eliasmith (2016). The basic idea is to use a differentiable approximation of the spiking neurons during the training process, and the actual spiking neurons during inference. NengoDL will perform these transformations automatically if the user tries to optimize a model containing a spiking neuron model that has an equivalent, differentiable rate-based implementation. In this example we will use these techniques to develop a network to classify handwritten digits (MNIST) in a spiking convolutional network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [TensorNodes](https://www.nengo.ai/nengo-dl/tensor-node.html) to construct the same network we constructed in ICE1 within Nengo. TensorNodes allow us to directly insert TensorFlow code into Nengo - making the parallels with standard deep networks very clear (i.e. the code looks the same!). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network(seed=0) as net:\n",
    "    # set some default parameters for the neurons that will make\n",
    "    # the training progress more smoothly\n",
    "    net.config[nengo.Ensemble].max_rates = nengo.dists.Choice([100])\n",
    "    net.config[nengo.Ensemble].intercepts = nengo.dists.Choice([0])\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "    neuron_type = nengo.LIF(amplitude=0.01)\n",
    "\n",
    "    # this is an optimization to improve the training speed,\n",
    "    # since we won't require stateful behaviour in this example\n",
    "    nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    # the input node that will be used to feed in input images\n",
    "    inp = nengo.Node(np.zeros(28 * 28))\n",
    "\n",
    "    # add the Flatten layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Flatten(input_shape=(28, 28)))(inp)\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    # add the first Dense layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Dense(128, activation=\"relu\"))(x)\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    # add the Dropout layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Dropout(0.2))(x)\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    # Final dense layer: readout\n",
    "    out = nengo_dl.Layer(tf.keras.layers.Dense(units=10))(x)\n",
    "\n",
    "    # we'll create two different output probes, one with a filter\n",
    "    # (for when we're simulating the network over time and\n",
    "    # accumulating spikes), and one without (for when we're\n",
    "    # training the network using a rate-based approximation)\n",
    "    out_p = nengo.Probe(out, label=\"out_p\")\n",
    "    out_p_filt = nengo.Probe(out, synapse=0.1, label=\"out_p_filt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a Simulator for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "Build finished in 0:00:00\n",
      "|#                         Optimizing graph                           | 0:00:00\n",
      "|#             Optimizing graph: operator simplificaton               | 0:00:00\n",
      "Optimizing graph: operator simplificaton finished in 0:00:00\n",
      "|#                Optimizing graph: merging operators                 | 0:00:00\n",
      "Optimizing graph: merging operators finished in 0:00:00\n",
      "|#                Optimizing graph: ordering signals                  | 0:00:00\n",
      "Optimizing graph: ordering signals finished in 0:00:00\n",
      "|#                Optimizing graph: creating signals                  | 0:00:00\n",
      "Optimizing graph: creating signals finished in 0:00:00\n",
      "Optimization finished in 0:00:00\n",
      "|#                        Constructing graph                          | 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaitlin.Fair\\AppData\\Local\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo_dl\\simulator.py:456: UserWarning: No GPU support detected. See https://www.nengo.ai/nengo-dl/installation.html#installing-tensorflow for instructions on setting up TensorFlow with GPU support.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|###           Constructing graph: build stage (5%)              | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (68%)             | ETA: 0:00:00\n",
      "|  #                      Constructing graph                          | 0:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "Construction finished in 0:00:00\n"
     ]
    }
   ],
   "source": [
    "minibatch_size = 256\n",
    "sim = nengo_dl.Simulator(net, minibatch_size=minibatch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set up our training/testing data. We need to incorporate time into this data, since Nengo models (and spiking neural networks in general) always contain a temporal aspect (think about the neurons in our brain! We don't feed our brain a photo and turn everything else off until we know what we are looking at. Our neurons are constantly taking in data and firing according to their receptive fields).\n",
    "\n",
    "When training the model we’ll be using a rate-based approximation, so we can run that for a single timestep. But when testing the model we’ll be using the spiking neuron models, so we need to run the model for multiple timesteps in order to collect the spike data over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add single timestep to training data\n",
    "train_images = train_images[:, None, :]\n",
    "train_labels = train_labels[:, None, None]\n",
    "\n",
    "# when testing our network with spiking neurons we will need to run it\n",
    "# over time, so we repeat the input/target data for a number of\n",
    "# timesteps.\n",
    "n_steps = 40\n",
    "test_images = np.tile(test_images[:, None, :], (1, n_steps, 1))\n",
    "test_labels = np.tile(test_labels[:, None, None], (1, n_steps, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quantify the network’s performance we’ll use a classification accuracy function (the percentage of test images classified correctly). We’re using a custom function here, because we only want to evaluate the output from the network on the final timestep (as we are simulating the network over time).\n",
    "\n",
    "You may recall that we used Sparse Categorical Crossentropy as our loss function for our Tensorflow network. This is related to the Sparse Categorical Accuracy metric. This is a metric used to evaluate the accuracy of a classification model. Specifically, it computes the accuracy of the predicted labels against the true labels. In the case of sparse categorical accuracy, it is designed for scenarios where the true labels are integers (sparse) and the predictions are probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(y_true, y_pred):\n",
    "    return tf.metrics.sparse_categorical_accuracy(y_true[:, -1], y_pred[:, -1])\n",
    "\n",
    "\n",
    "# note that we use `out_p_filt` when testing (to reduce the spike noise)\n",
    "sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "\n",
    "# print(\n",
    "#    \"Accuracy before training:\",\n",
    "#    sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network! For training we’ll use the standard categorical cross entropy loss function, and the Adam optimizer.\n",
    "\n",
    "This will take about 45 seconds to run. You can mess with the number of epochs, the minibatch size, or the number of time steps to speed things up. *If you do, note what changes in your results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kaitlin.Fair\\AppData\\Local\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo_dl\\simulator.py:1892: UserWarning: Number of elements in input data (60000) is not evenly divisible by Simulator.minibatch_size (256); input data will be truncated.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|##########    Constructing graph: build stage (15%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|##############Constructing graph: build stage (26%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (63%)             | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "234/234 [==============================] - 11s 35ms/step - loss: 0.5026 - out_p_loss: 0.5026\n",
      "Epoch 2/5\n",
      "234/234 [==============================] - 8s 36ms/step - loss: 0.2662 - out_p_loss: 0.2662\n",
      "Epoch 3/5\n",
      "234/234 [==============================] - 10s 42ms/step - loss: 0.2269 - out_p_loss: 0.2269\n",
      "Epoch 4/5\n",
      "234/234 [==============================] - 9s 40ms/step - loss: 0.1969 - out_p_loss: 0.1969\n",
      "Epoch 5/5\n",
      "234/234 [==============================] - 9s 38ms/step - loss: 0.1761 - out_p_loss: 0.1761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x247a02b7be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run training\n",
    "sim.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss={out_p: tf.losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    ")\n",
    "sim.fit(train_images, {out_p: train_labels}, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the classification accuracy again.\n",
    "\n",
    "This will take about 30-45 seconds to run (not sure why - bonus points if you figure it out). You can check the accuracy for a fraction of the results to speed things up (recall, there are 10,000 test images). *If you do, note the impact on your results.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "print(\n",
    "    \"Accuracy after training:\",\n",
    "    sim.evaluate(\n",
    "        test_images[0 : 256 * 3], {out_p_filt: test_labels[0 : 256 * 3]}, verbose=0\n",
    "    )[\"loss\"],\n",
    "    # sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the spiking neural network is achieving ~95% accuracy, which is what we would expect for MNIST. n_steps could be increased to further improve performance, since we would get a more accurate measure of each spiking neuron’s output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sim.predict(test_images[:minibatch_size])\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(test_images[i, 0].reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(tf.nn.softmax(data[out_p_filt][i]))\n",
    "    plt.legend([str(i) for i in range(10)], loc=\"upper left\")\n",
    "    plt.xlabel(\"timesteps\")\n",
    "    plt.ylabel(\"probability\")\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
