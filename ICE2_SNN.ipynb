{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE495 In-class Exercise 2: Spiking Neural Networks using NengoDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ICE uses NengoDL and TensorFlow's Keras to:\n",
    "\n",
    "1. Load a prebuilt dataset.\n",
    "2. Build a simple *spiking* neural network that classifies images.\n",
    "3. Train the spiking neural network.\n",
    "4. Evaluate the accuracy of the spiking network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up\n",
    "\n",
    "**Ensure you are using your [495 Virtual Environment](https://github.com/kaitlin-fair/495venv_setup) before you begin!**  \n",
    "  \n",
    "If you are using your virtual environment, the next section should run without issue. If you are not in your virtual environment (or your environment did not install properly), you'll see a lot of red.\n",
    "  \n",
    "Import Nengo, NengoDL, TensorFlow and other supporting libraries into your program to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "import nengo\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nengo_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset\n",
    "\n",
    "Load and prepare the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database). The pixel values of the images range from 0 through 255. Recall in ICE1, we had to normalize the values. For this spiking neural network, we do not have to do that. Ensure you understand why we don't have to normalize the input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAAqCAYAAACHtsc9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAE1klEQVR4nO3dP0jV/x7H8be3Wx0pHCwFhQbpFAQmNZghFdmWQ0VJNBZFm1IQRKAFQS1F2BZO/aEpIYKGoEKJ8B9BBeJgEEWZg0agRFqZv+kK4l2uv+7vc772eMAZzue7PNcX3+/3nKLZ2dnZAAAAgIz6V+oAAAAA+DsMWwAAADLNsAUAACDTDFsAAAAyzbAFAAAg0wxbAAAAMs2wBQAAINMMWwAAADLNsAUAACDTDFsAAAAyzbBl0bq7u6OoqOi/fvr6+lLnASQ1PT0dZ8+ejcrKyiguLo66urp4/Phx6iyAgnPp0qUoKiqK6urq1Clk2L9TB5B9LS0tUVtbO+8sn88nqgEoDEePHo3Ozs44depUbNiwIW7evBmNjY3R1dUVO3bsSJ0HUBA+fvwYly9fjlWrVqVOIeOKZmdnZ1NHkE3d3d3R0NAQ9+7di6amptQ5AAVjYGAg6urq4sqVK3HmzJmIiJiamorq6uooLy+Pnp6exIUAheHIkSMxNjYWMzMzMT4+HoODg6mTyCiPIvNbTE5Oxs+fP1NnABSEzs7OWLZsWZw8eXLuLJfLxfHjx6O3tzc+fPiQsA6gMDx79iw6Ozujvb09dQpLgGHL33bs2LEoKSmJXC4XDQ0N8eLFi9RJAEm9fPkyNm7cGCUlJfPOt23bFhERr169SlAFUDhmZmaiubk5Tpw4EZs3b06dwxLgHVsWbcWKFXHo0KFobGyMtWvXxtDQUFy9ejV27twZPT09sXXr1tSJAEmMjo5GRUXFgvP/nH369OmfTgIoKDdu3Ij379/HkydPUqewRBi2LFp9fX3U19fPfd+3b180NTVFTU1NnDt3Lh49epSwDiCdb9++xcqVKxec53K5uesAf6rPnz/H+fPno62tLcrKylLnsER4FJnfKp/Px/79+6OrqytmZmZS5wAkUVxcHNPT0wvOp6am5q4D/KlaW1ujtLQ0mpubU6ewhLhjy2+3bt26+P79e3z9+nXB+2UAf4KKiooYGRlZcD46OhoREZWVlf90EkBBePPmTXR0dER7e/u81zKmpqbix48f8e7duygpKYnS0tKElWSRO7b8dm/fvo1cLherV69OnQKQxJYtW2J4eDgmJibmnff3989dB/gTjYyMxK9fv6KlpSWqqqrmPv39/TE8PBxVVVVx8eLF1JlkkP+xZdHGxsYWvBfx+vXrqK2tjb1798aDBw8SlQGk1d/fH9u3b5/3P7bT09NRXV0da9asib6+vsSFAGmMj4/H8+fPF5y3trbG5ORkXL9+PdavX++XkvmfGbYs2p49e6K4uDjq6+ujvLw8hoaGoqOjI5YvXx69vb2xadOm1IkAyRw+fDju378fp0+fjnw+H7du3YqBgYF4+vRp7Nq1K3UeQEHZvXt3jI+Px+DgYOoUMso7tizagQMH4u7du3Ht2rWYmJiIsrKyOHjwYFy4cCHy+XzqPICkbt++HW1tbXHnzp348uVL1NTUxMOHD41aAPg/cMcWAACATPPjUQAAAGSaYQsAAECmGbYAAABkmmELAABAphm2AAAAZJphCwAAQKYZtgAAAGSaYQsAAECmGbYAAABkmmELAABAphm2AAAAZJphCwAAQKYZtgAAAGSaYQsAAECmGbYAAABkmmELAABAphm2AAAAZNpfY8A7lsRv6ukAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# flatten images - note that they do not use a layer that flattens\n",
    "#   the data and instead pre-process the data to flatten \n",
    "#   The layer cannot handle a 4 dimensional input = image#, timestep, xdim, ydim\n",
    "#   Flatten to make it 3-D: image#, timestep, xdim*ydim\n",
    "#train_images = train_images.reshape((train_images.shape[0], -1))\n",
    "#test_images = test_images.reshape((test_images.shape[0], -1))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    #plt.imshow(np.reshape(train_images[i], (28, 28)), cmap=\"gray\")\n",
    "    plt.imshow(train_images[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(str(train_labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all deep learning methods are based on gradient descent, which means that the network being optimized needs to be differentiable. Deep neural networks are usually built using rectified linear or sigmoid neurons, as these are differentiable nonlinearities. However, in neurmorphic modelling we often want to use spiking neurons, which are not differentiable. So the challenge is how to apply deep learning methods to spiking neural networks.\n",
    "\n",
    "A method for accomplishing this is presented in Hunsberger and Eliasmith (2016). The basic idea is to use a differentiable approximation of the spiking neurons during the training process, and the actual spiking neurons during inference. NengoDL will perform these transformations automatically if the user tries to optimize a model containing a spiking neuron model that has an equivalent, differentiable rate-based implementation. In this example we will use these techniques to develop a network to classify handwritten digits (MNIST) in a spiking convolutional network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [TensorNodes](https://www.nengo.ai/nengo-dl/tensor-node.html) to construct the same network we constructed in ICE1 within Nengo. TensorNodes allow us to directly insert TensorFlow code into Nengo - making the parallels with standard deep networks very clear (i.e. the code looks the same!). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network(seed=0) as net:\n",
    "    # set some default parameters for the neurons that will make\n",
    "    # the training progress more smoothly\n",
    "    net.config[nengo.Ensemble].max_rates = nengo.dists.Choice([100])\n",
    "    net.config[nengo.Ensemble].intercepts = nengo.dists.Choice([0])\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "    neuron_type = nengo.LIF(amplitude=0.01)\n",
    "\n",
    "    # this is an optimization to improve the training speed,\n",
    "    # since we won't require stateful behaviour in this example\n",
    "    nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    # the input node that will be used to feed in input images\n",
    "    inp = nengo.Node(np.zeros(28 * 28))\n",
    "\n",
    "    # add the Flatten layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Flatten(input_shape=(28, 28)))(inp)\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    # add the first Dense layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Dense(128, activation=\"relu\"))(x)\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    # add the Dropout layer\n",
    "    x = nengo_dl.Layer(tf.keras.layers.Dropout(0.2))(x)\n",
    "    x = nengo_dl.Layer(neuron_type)(x)\n",
    "\n",
    "    # Final dense layer: readout\n",
    "    out = nengo_dl.Layer(tf.keras.layers.Dense(units=10))(x)\n",
    "\n",
    "    # we'll create two different output probes, one with a filter\n",
    "    # (for when we're simulating the network over time and\n",
    "    # accumulating spikes), and one without (for when we're\n",
    "    # training the network using a rate-based approximation)\n",
    "    out_p = nengo.Probe(out, label=\"out_p\")\n",
    "    out_p_filt = nengo.Probe(out, synapse=0.1, label=\"out_p_filt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a Simulator for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     Building network (0%)                    | ETA:  --:--:--\n",
      "|#####################Building network (88%)#############        | ETA: 0:00:00\n",
      "Build finished in 0:00:00\n",
      "|#                         Optimizing graph                           | 0:00:00\n",
      "|#             Optimizing graph: operator simplificaton               | 0:00:00\n",
      "Optimizing graph: operator simplificaton finished in 0:00:00\n",
      "|#                Optimizing graph: merging operators                 | 0:00:00\n",
      "Optimizing graph: merging operators finished in 0:00:00\n",
      "|#                Optimizing graph: ordering signals                  | 0:00:00\n",
      "Optimizing graph: ordering signals finished in 0:00:00\n",
      "|#                Optimizing graph: creating signals                  | 0:00:00\n",
      "Optimizing graph: creating signals finished in 0:00:00\n",
      "Optimization finished in 0:00:00\n",
      "|#                        Constructing graph                          | 0:00:00\n",
      "| #                       Constructing graph                          | 0:00:00\n",
      "|           Constructing graph: pre-build stage (0%)           | ETA:  --:--:--\n",
      "Constructing graph: pre-build stage finished in 0:00:00\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|             Constructing graph: build stage (0%)             | ETA:  --:--:--\n",
      "|##########    Constructing graph: build stage (15%)             | ETA: 0:00:01\n",
      "|##############Constructing graph: build stage (26%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (36%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (47%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (63%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (68%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (78%)             | ETA: 0:00:00\n",
      "|##############Constructing graph: build stage (89%)######       | ETA: 0:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "|############Constructing graph: build stage (100%)############| ETA:  00:00:00\n",
      "Constructing graph: build stage finished in 0:00:00\n",
      "|           #             Constructing graph                          | 0:00:01\n",
      "Construction finished in 0:00:01\n"
     ]
    }
   ],
   "source": [
    "minibatch_size = 256\n",
    "sim = nengo_dl.Simulator(net, minibatch_size=minibatch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set up our training/testing data. We need to incorporate time into this data, since Nengo models (and spiking neural networks in general) always contain a temporal aspect (think about the neurons in our brain! We don't feed our brain a photo and turn everything else off until we know what we are looking at. Our neurons are constantly taking in data and firing according to their receptive fields).\n",
    "\n",
    "When training the model we’ll be using a rate-based approximation, so we can run that for a single timestep. But when testing the model we’ll be using the spiking neuron models, so we need to run the model for multiple timesteps in order to collect the spike data over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add single timestep to training data\n",
    "train_images = train_images[:, None, :]\n",
    "train_labels = train_labels[:, None, None]\n",
    "\n",
    "# when testing our network with spiking neurons we will need to run it\n",
    "# over time, so we repeat the input/target data for a number of\n",
    "# timesteps.\n",
    "n_steps = 40\n",
    "test_images = np.tile(test_images[:, None, :], (1, n_steps, 1))\n",
    "test_labels = np.tile(test_labels[:, None, None], (1, n_steps, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quantify the network’s performance we’ll use a classification accuracy function (the percentage of test images classified correctly). We’re using a custom function here, because we only want to evaluate the output from the network on the final timestep (as we are simulating the network over time).\n",
    "\n",
    "You may recall that we used Sparse Categorical Crossentropy as our loss function for our Tensorflow network. This is related to the Sparse Categorical Accuracy metric. This is a metric used to evaluate the accuracy of a classification model. Specifically, it computes the accuracy of the predicted labels against the true labels. In the case of sparse categorical accuracy, it is designed for scenarios where the true labels are integers (sparse) and the predictions are probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(y_true, y_pred):\n",
    "    return tf.metrics.sparse_categorical_accuracy(y_true[:, -1], y_pred[:, -1])\n",
    "\n",
    "\n",
    "# note that we use `out_p_filt` when testing (to reduce the spike noise)\n",
    "sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "\n",
    "# print(\n",
    "#    \"Accuracy before training:\",\n",
    "#    sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network! For training we’ll use the standard categorical cross entropy loss function, and the Adam optimizer.\n",
    "\n",
    "This will take about 45 seconds to run. You can mess with the number of epochs, the minibatch size, or the number of time steps to speed things up. *If you do, note what changes in your results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "node data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# run training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m sim\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m      4\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{out_p: tf\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)},\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m \u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mout_p\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DFEC\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo\\utils\\magic.py:179\u001b[0m, in \u001b[0;36mBoundFunctionWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper(wrapped, instance, args, kwargs)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\DFEC\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo_dl\\simulator.py:63\u001b[0m, in \u001b[0;36mrequire_open\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SimulatorClosed(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwrapped\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after simulator is closed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DFEC\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo_dl\\simulator.py:858\u001b[0m, in \u001b[0;36mSimulator.fit\u001b[1;34m(self, x, y, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    856\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_data\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (x_val, y_val, validation_data[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 858\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_keras(\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, n_steps\u001b[38;5;241m=\u001b[39mn_steps, stateful\u001b[38;5;241m=\u001b[39mstateful, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    860\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\DFEC\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo\\utils\\magic.py:179\u001b[0m, in \u001b[0;36mBoundFunctionWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper(wrapped, instance, args, kwargs)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__wrapped__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\DFEC\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo_dl\\simulator.py:46\u001b[0m, in \u001b[0;36mwith_self\u001b[1;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(instance\u001b[38;5;241m.\u001b[39mtensor_graph\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m---> 46\u001b[0m         output \u001b[38;5;241m=\u001b[39m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mset_floatx(keras_dtype)\n",
      "File \u001b[1;32mc:\\Users\\DFEC\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo_dl\\simulator.py:953\u001b[0m, in \u001b[0;36mSimulator._call_keras\u001b[1;34m(self, func_type, x, y, n_steps, stateful, **kwargs)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# TODO: apply standardize/generate/check data to generator somehow\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# maybe move it into a callback where the generated data is available?\u001b[39;00m\n\u001b[0;32m    952\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_inputs(x, n_steps\u001b[38;5;241m=\u001b[39mn_steps)\n\u001b[1;32m--> 953\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminibatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_batch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    960\u001b[0m     input_steps \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\DFEC\\anaconda3\\envs\\py3.10-nengo3.2\\lib\\site-packages\\nengo_dl\\simulator.py:1929\u001b[0m, in \u001b[0;36mSimulator._check_data\u001b[1;34m(self, data, batch_size, n_steps, nodes)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;66;03m# generic shape checks\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1929\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have rank 3 (batch_size, n_steps, dimensions), found rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1931\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1932\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1933\u001b[0m     )\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch_size:\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\n\u001b[0;32m   1936\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size of data (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) less than Simulator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1937\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`minibatch_size` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1938\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1939\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: node data: should have rank 3 (batch_size, n_steps, dimensions), found rank 4"
     ]
    }
   ],
   "source": [
    "# run training\n",
    "sim.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss={out_p: tf.losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    ")\n",
    "sim.fit(train_images, {out_p: train_labels}, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the classification accuracy again.\n",
    "\n",
    "This will take about 30-45 seconds to run (not sure why - bonus points if you figure it out). You can check the accuracy for a fraction of the results to speed things up (recall, there are 10,000 test images). *If you do, note the impact on your results.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.compile(loss={out_p_filt: classification_accuracy})\n",
    "print(\n",
    "    \"Accuracy after training:\",\n",
    "    sim.evaluate(\n",
    "        test_images[0 : 256 * 3], {out_p_filt: test_labels[0 : 256 * 3]}, verbose=0\n",
    "    )[\"loss\"],\n",
    "    # sim.evaluate(test_images, {out_p_filt: test_labels}, verbose=0)[\"loss\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the spiking neural network is achieving ~95% accuracy, which is what we would expect for MNIST. n_steps could be increased to further improve performance, since we would get a more accurate measure of each spiking neuron’s output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sim.predict(test_images[:minibatch_size])\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(test_images[i, 0].reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(tf.nn.softmax(data[out_p_filt][i]))\n",
    "    plt.legend([str(i) for i in range(10)], loc=\"upper left\")\n",
    "    plt.xlabel(\"timesteps\")\n",
    "    plt.ylabel(\"probability\")\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
